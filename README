/*** LAUNCH PROJECT ***/
Execute download_repo.bat : git clone the llm model of phi3 from hugging face (no token required)

Set  envirronement 
install python 3.10

install VINO
python -m venv vino
.\vino\Scripts\Activate.ps1

set install this dep versions (CPU only car architecture non cuda dans mon cas de mon intel arc dédié (XPU)
-----------------------------------------------------
pip list | findstr torch : |
-------------------------
directML		    
// impossible de faire marcher le support pour mon XPU car gestion des packages 4bytes (quantization) non natif comme sur CUDA
torch                       2.1.1
torchaudio                  2.1.1
torchvision                 0.16.1
-----------------------------------------------------

set VINO ENV : 
> execute_vino.bat -> .\vino\Scripts\Activate.ps1

*** Required ***
pip install --upgrade pip
pip install torch torchvision torchaudio
pip install sentence-transformers faiss-cpu
pip install llama-index tavily-python

>launch download_repo.bat // pour télécharger les models requis, il faut changer le config.py avec le nom exacte du model a utiliser (model llama obligatoire)

######	LAUNCHER ######

> cd project 
> python server.py // launch the server for web request (prompt)
> python main.py // launch le deep learning Lora en fine turne (tres long sur CPU)
> python launch_rag.py // va faire des chunks avec faiss pour recherche rapide et prioritaire sans réétrainer le mode 
// mettre les archive a persister dans : project/RAG/archive (script recursif)

######	FRONT - CHAT BOX IA ######

Execute index in a brower : C:\Users\come_\Desktop\ia-llm\phi3\ui-chatbox\index.html



grafcet execution : 

PLC / Ingestion
      ↓
PostgreSQL (INSERT)
      ↓
LISTEN / NOTIFY  ← (événement DB)
      ↓
Worker Python (thread)
      ↓
Détection d’anomalies
      ↓
SocketIO.emit()
      ↓
Frontend (Vue / Vite)